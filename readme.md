# Bondareva Alina DAG#

Этот проект реализует DAG в Apache Airflow для ежемесячного расчета витрины активности клиентов по сумме и количеству их транзакций.

## Описание задачи

DAG'и выполняют следующие шаги:

1. **Extract**: Скачивание данных из CSV файла, содержащего суммы и количество транзакций по продуктам для каждого клиента.
2. **Transform**: Обработка данных с использованием функции `transfrom` для создания таблицы флагов активности клиентов по продуктам.
3. **Load**: Сохранение трансформированных данных в CSV файл, не перезаписывая данные предыдущих расчетов.

## Структура проекта

- `DAG1_Bondareva.py`: Основной файл DAG, содержащий логику ETL процесса.
- `DAG2_Bondareva.py`: Дополненный файл DAG, реализующий распараллеленную логику по каждому продукту.
- `transform_script.py`: Содержит обновленную функцию `transform`, реализующую трансформацию данных. 

## Настройка и запуск

### Предварительные требования

- Установлен Apache Airflow.
- Установлены необходимые Python библиотеки: `requests`, `pandas`, `pendulum`.

### Настройка Airflow

1. Скопируйте файлы `DAG1_Bondareva.py`, `DAG2_Bondareva.py` и `transform_script.py` в директорию `dags` вашего Airflow.
2. Обновите настройки Airflow для включения DAG:
    ```bash
    airflow db init
    airflow webserver --port 8080
    airflow scheduler
    ```
3. Зайдите в веб-интерфейс Airflow (по умолчанию: `http://localhost:8080`) и активируйте DAG с именем `Bondareva_Alina_dag{num}`.

### Структура DAG

- `DownloadData`: Задача для скачивания данных и сохранения их во временную директорию `/tmp/airflow/data/`.
- `ProcessProduct`: Создается 10 задач, по одной для каждого продукта (от `a` до `j`). Обрабатывает данные и сохраняет результаты.

### Перезапись данных из временной директории

Результаты обработки данных сохраняются во временную директорию `/tmp/airflow/data/`. Чтобы перенести эти данные в постоянное хранилище, выполните следующие шаги:

1. Скопируйте файлы из временной директории в нужное место:
    ```bash
    cp /tmp/airflow/data/flags_activity_* /path/to/your/storage/
    ```
2. Убедитесь, что права доступа к файлам установлены корректно:
    ```bash
    chmod 755 /path/to/your/storage/flags_activity_*
    ```

## Примечания

- DAG настроен для запуска 5-го числа каждого месяца в 00:00.
- В случае ошибки задачи будет выполнено до 3 попыток с задержкой в 60 секунд между ними.
- Используется временная директория `/tmp/airflow/data/` для хранения данных, так как при выполнении задания были проблемы с правами `PermissionError: [Errno 13] Permission denied`.